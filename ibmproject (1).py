# -*- coding: utf-8 -*-
"""ibmproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18wbILZ1Gc7zbJHR8rM-bV3kMl2Dae03w
"""

!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 \
langgraph langchain langchain-google-genai openai



import os
import getpass
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage,AIMessage
from typing_extensions import TypedDict
from typing import Annotated

os.environ["GOOGLE_API_KEY"]= getpass.getpass("enter your Gemini API key")

llm=ChatGoogleGenerativeAI(model="models/gemini-1.5-flash-latest", temperature=0.2)

class state(TypedDict):
  messages: Annotated[list,add_messages]
  classification:str
  need: str # Add 'need' to the state definition

def ask_need(state: state)->state:
  # Removed interactive input. Assuming 'need' is provided in the initial state.
  # need=input("Hi! How can i assist you today regarding good health and well-being?")
  # state["need"]=need # This line is no longer needed here
  return state

def classify_need(state: state):
  # Ensure 'need' is accessed correctly from the state
  prompt =(
      "you are helpful good health and well-being promoter. classify the need below into of the categories:\n"
      "-Nutrition\n -sanitation\n -healthy food\n" # Corrected "food security" to "healthy food" based on router logic
      f"need :{state['need']}\n"
  )
  response=llm.invoke([HumanMessage(content=prompt)])
  category=response.content.strip()
  print(f"LLM classifies the need as:{category}") #debug
  state["classification"]=category
  return state

def need_router(state:state)-> str:
  last=state["classification"].lower()
  if "nutrition" in last:
    cat="nutrition"
  elif "sanitation" in last or "worker" in last:
    cat="sanitation"
  elif "hunger" in last or "healthy food" in last:
    cat="healthy_food"
  else:
    cat="general"
  return cat

#def route_need(state;state)-> str:
#return state["classification"]

def respond_healthy_food(state:state):
  state["messages"]: state["need"] + [AIMessage(content="Here's help on reducing junk food and boosting healthy food")]
  return state
def respond_nutrition(state:state):
  state["messages"]: state["need"] + [AIMessage(content="let's talk about improving nutrition and dietary quality")]
  return state
def respond_sanitation(state: state):
  state["messages"]: state["need"] + [AIMessage(content="i can share suitable sanitation practices and support workers")]
  return state
def respond_general(state: state):
  state["messages"]: state["need"] + [AIMessage(content="general review towards the good health and well-being")]
  return state

from typing_extensions import TypedDict
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph.message import add_messages
from typing import Annotated # Import Annotated if not already imported

class state(TypedDict):
  messages: Annotated[list, add_messages]
  classification: str
  need: str # Add 'need' to the state definition

graph=StateGraph(state)
graph.set_entry_point("ask_need") # Keep ask_need as entry point, but it now just passes the initial state
graph.add_node("ask_need",ask_need)
graph.add_node("classify_need",classify_need)
graph.add_node("respond_healthy_food",respond_healthy_food)
graph.add_node("respond_nutrition",respond_nutrition)
graph.add_node("respond_sanitation",respond_sanitation)
graph.add_node("respond_general",respond_general)

graph.add_edge("ask_need","classify_need")
graph.add_conditional_edges("classify_need", need_router,{
    "healthy_f00d":"respond_healthy_food",
    "nutrition":"respond_nutrition",
    "sanitation":"respond_sanitation",
    "general":"respond_general"
})
graph.add_edge("respond_healthy_food",END)
graph.add_edge("respond_nutrition",END)
graph.add_edge("respond_sanitation",END)
graph.add_edge("respond_general",END)

app=graph.compile()

from langchain_core.messages import AIMessage
ai_messages=[msg for msg in state["messages"]if isinstance(msg, AIMessage)]

if ai_messages:
  print(ai_messages[-1].content)
final_state=app.invoke({})
print("final output\n")
print(final_state[AIMessage])

